{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Salary_Data.csv')\n",
    "x = dataset.iloc[:, 0].values #Feature matrix\n",
    "y = dataset.iloc[:, 1].values #Label Matrix \n",
    "plt.scatter(x,y,color='black')\n",
    "plt.xlabel(\"Years of Experience\", fontsize=12);\n",
    "plt.ylabel(\"Salary\", rotation=90, fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimos cuadrados\n",
    "## Solución analítica univariable\n",
    "modelo\n",
    "$\\Large{y=mx+b}$\n",
    "\n",
    "función de error\n",
    "$ \\varepsilon (m,b)=\\sum_{i=1}^{N} (y-mx-b)^2 $\n",
    "\n",
    "$\\Large{m= \\frac{N \\sum_{i=1}^{N} {x_iy_i}- \\sum_{i=1}^{N}{y_i} \\sum_{i=1}^{N}{x_i}}{N \\sum_{i=1}^{N}{x_i^2} - (\\sum_{i=1}^{N}{x_i})^2}}$\n",
    "\n",
    "$\\Large{b=   \\frac{\\sum_{i=1}^{N}{y_i} \\sum_{i=1}^{N}{x_i^2}- \\sum_{i=1}^{N} {x_iy_i}\\sum_{i=1}^{N}{x_i}} {N \\sum_{i=1}^{N}{x_i^2}-(\\sum_{i=1}^{N}{x_i})^2  }}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "RMS = 5592.043609\n"
     ]
    }
   ],
   "source": [
    "#parameter estimation\n",
    "N=len(x)\n",
    "print(len(x))\n",
    "sumxy=np.sum(x*y)\n",
    "sumy=np.sum(y)\n",
    "sumx=np.sum(x)\n",
    "sumx2=sumx**2\n",
    "sumxx=np.sum(x**2)\n",
    "m= (N*sumxy - sumy*sumx)/(N*sumxx- sumx2)\n",
    "b=(sumy*sumxx-sumxy*sumx)/(N*sumxx- sumx2)\n",
    "\n",
    "\n",
    "#plot \n",
    "x_p=np.array([np.min(x),np.max(x)])\n",
    "y_p=m*x_p+b\n",
    "plt.plot(x_p,y_p,'r-')\n",
    "plt.plot(x,y,'b.')\n",
    "plt.xlabel(\"Years of Experience\", fontsize=12);\n",
    "plt.ylabel(\"Salary\", rotation=90, fontsize=12);\n",
    "plt.title('model: m=%f,'  %m +' b=%f'  %b)\n",
    "\n",
    "#RMS\n",
    "rms = mean_squared_error(y,m*x+b , squared=False)\n",
    "print(\"RMS = %f\" %rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función objetivo por gradiente descendente clásico\n",
    "\n",
    "\n",
    "- Ejemplo de hipótesis: regresión lineal \n",
    "\\begin{equation*}\n",
    "y=h(\\mathbf{x} \\boldsymbol{\\theta})= h_{\\boldsymbol{\\theta}}(\\mathbf{x})= \\theta_0+\\theta_1x_1+\\cdots + \\theta_n x_n\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "- Convención para simplificar notación: $x_0={1}$\n",
    "\\begin{equation*}\n",
    "y=h(\\mathbf{x}; \\boldsymbol{\\theta})= h_{\\boldsymbol{\\theta}}(\\mathbf{x})= \\theta_0x_0+\\theta_1x_1+\\cdots + \\theta_n x_n=\\sum_{i=0}^{n}{\\theta_{i}x_{i}}\n",
    "\\end{equation*} \n",
    "\\begin{equation*}\n",
    "=\\boldsymbol{\\theta}^T  \\mathbf{x}= \\langle \\boldsymbol{\\theta},  \\mathbf{x} \\rangle= \\boldsymbol{\\theta} \\cdot{}  \\mathbf{x}\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "\\boldsymbol{\\theta} = [\\theta_{0},\\theta_{1}, \\ldots ,\\theta_{n}]^T\n",
    "\\end{equation*}  \n",
    "\\begin{equation*}\n",
    "\\boldsymbol{x} = [x_{0},x_{1}, \\ldots ,x_{n}]^T\n",
    "\\end{equation*}  \n",
    "\n",
    "\n",
    "- Para encontrar $\\boldsymbol{\\theta}$ minimizamos la función de error $J(\\boldsymbol{\\theta})$ con \n",
    "\\begin{equation*}\n",
    "J(\\boldsymbol{\\theta}) = \\frac{1}{2} \\sum_{i=1}^{m} ( h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)})- y^{(i)} )^2\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    " \\boldsymbol{\\theta}^{*}= \\arg\\min_{\\boldsymbol{\\theta}} \\boldsymbol{\\theta}\n",
    "\\end{equation*}\n",
    "Objetivo:\n",
    "Se buscan parámetros $\\boldsymbol{\\theta}$ que producen el menor valor de $\\boldsymbol{\\theta}$\n",
    "\n",
    "- Para el caso de dos parametros una caraterística\n",
    "\\begin{equation*}\n",
    "J(\\theta_0,\\theta_1) = \\frac{1}{2}  \\sum_{i=1}^{m}  ( \\theta_0+\\theta_1 x_{1}^{(i)} - y^{(i)} )^2\n",
    "\\end{equation*}  \n",
    "\n",
    "### Algoritmo de gradiente descendente  \n",
    "\n",
    "1.- Tome un valor $\\boldsymbol{\\theta}^{(0)}$ inicial, t=0\n",
    "\n",
    "2.- Calcule en   $\\boldsymbol{\\theta}^{(t)}$ el gradiente (máxima dirección de cambio)\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\boldsymbol{\\theta}}  J(\\boldsymbol{\\theta}^{(t)})= \\left[ \\frac{\\partial J}{\\partial \\theta_{0}}  \\frac{\\partial J}{\\partial \\theta_{1}}  \\cdots \\frac{\\partial J}{\\partial \\theta_{0}} \\right]^{T} \n",
    "\\end{equation*}\n",
    "3.- Calcule la nueva posición \n",
    "\\begin{equation*}\n",
    "{\\boldsymbol{\\theta}}^{(t+1)}:= {\\boldsymbol{\\theta}}^{(t)}- \\alpha \\nabla_{\\boldsymbol{\\theta}}  J(\\boldsymbol{\\theta}^{(t)})\n",
    "\\end{equation*}\n",
    "o de forma equivalente para cada $\\theta_{j}, j\\in 1, \\ldots ,n$\n",
    "\\begin{equation*}\n",
    "\\theta_{j}^{(t+1)}:=\\theta_{j}^{(t)}- \\alpha \\frac{\\partial J({\\boldsymbol{\\theta}}^{(t)})}{\\partial \\theta_j}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "### Gradiente de la función de costo\n",
    "La función de costo multivariable esta dada por \n",
    " \\begin{equation*}\n",
    " J(\\theta_0,\\theta_1, \\theta_2, \\ldots)= \\frac{1}{2} \\sum_{i=1}^{m}(\\theta_0+\\theta_1 x_1^{(i)}+ \\theta_2 x_2^{(i)}+ \\ldots + \\theta_n x_n^{(i)}-y^{(i)})^2\n",
    "\\end{equation*}\n",
    "el gradiente se obtiene fácilmente\n",
    "\n",
    "   \\begin{align}\n",
    "    \\nabla_\\theta J(\\boldsymbol{\\theta}) &= \\begin{bmatrix}\n",
    "            \\frac{\\partial J({\\boldsymbol{\\theta}})}{\\partial \\theta_0} \\\\\n",
    "           \\frac{\\partial J({\\boldsymbol{\\theta}})}{\\partial \\theta_1} \\\\\n",
    "           \\frac{\\partial J({\\boldsymbol{\\theta}})}{\\partial \\theta_2} \\\\\n",
    "           \\vdots  \\\\\n",
    "           \\frac{\\partial J({\\boldsymbol{\\theta}})}{\\partial \\theta_n}\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}\n",
    "  \n",
    "  \n",
    " \\begin{align}\n",
    "    \\nabla_\\theta J(\\boldsymbol{\\theta}) &= \\begin{bmatrix}\n",
    "            \\sum_{i=1}^{m} (\\theta_0+\\theta_1 x_1^{(i)}+ \\theta_2 x_2^{(i)}+ \\ldots + \\theta_n x_n^{(i)}-y^{(i)}) \\cdot 1 \\\\\n",
    "           \\sum_{i=1}^{m} (\\theta_0+\\theta_1 x_1^{(i)}+ \\theta_2 x_2^{(i)}+ \\ldots + \\theta_n x_n^{(i)}-y^{(i)}) \\cdot x_1^{(i)}\\\\\n",
    "           \\sum_{i=1}^{m} (\\theta_0+\\theta_1 x_1^{(i)}+ \\theta_2 x_2^{(i)}+ \\ldots + \\theta_n x_n^{(i)}-y^{(i)}) \\cdot x_2^{(i)}\\\\\n",
    "           \\vdots  \\\\\n",
    "           \\sum_{i=1}^{m} (\\theta_0+\\theta_1 x_1^{(i)}+ \\theta_2 x_2^{(i)}+ \\ldots + \\theta_n x_n^{(i)}-y^{(i)}) \\cdot x_n^{(i)}\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}\n",
    "\n",
    "gradiente en notación vectorial\n",
    "\n",
    " \\begin{equation*}\n",
    "\\nabla_\\theta J(\\boldsymbol{\\theta}) = \\sum_{i=1}^{m}(\\boldsymbol{\\theta}^T \\boldsymbol{x}^{(i)}-y^{(i)}) \\cdot \\boldsymbol{x}^{(i)}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo de gradiente descendente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 2238\n",
      "analytic: b=25792.200199, m=9449.962321,  \n",
      "DG: b=25792.184795 m=9449.964607,\n",
      "RMS_analytic = 5592.043609\n",
      "RMS_gradient = 5592.043609\n"
     ]
    }
   ],
   "source": [
    "theta = np.array([[0],[0]])\n",
    "ep=1e-4\n",
    "lr =0.001\n",
    "n_iter = 3000\n",
    "y=y.reshape((len(y), 1))\n",
    "x_b = np.c_[np.ones((len(x),1)),x]\n",
    "for it in range(n_iter):\n",
    "    #Gradient\n",
    "    pred = np.dot(x_b,theta)\n",
    "    si=-lr*(x_b.T.dot((pred - y)))\n",
    "    theta = theta + si\n",
    "    if LA.norm(si)<ep:\n",
    "        break\n",
    "print(\"Iterations: %d\" %it)\n",
    "print(\"analytic: b=%f, m=%f,  \\nDG: b=%f m=%f,\" %(b,m,theta[0],theta[1]))\n",
    "rms = mean_squared_error(y,m*x+b , squared=False)\n",
    "print(\"RMS_analytic = %f\" %rms)\n",
    "rms = mean_squared_error(y,theta[1]*x+theta[0] , squared=False)\n",
    "print(\"RMS_gradient = %f\" %rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23a2a703af0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot \n",
    "x_p=np.array([np.min(x),np.max(x)])\n",
    "y_g=theta[1]*x_p+theta[0]\n",
    "plt.plot(x_p,y_p,'r-')\n",
    "plt.plot(x_p,y_g,'g--')\n",
    "plt.plot(x,y,'b.')\n",
    "plt.xlabel(\"Years of Experience\", fontsize=12);\n",
    "plt.ylabel(\"Salary\", rotation=90, fontsize=12);\n",
    "plt.legend([\"Analytic\", \"Descent Gradient\"], loc =\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 600\n",
      "0\n",
      "(800, 600) (800, 600)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#analytic: b=25792.200199, m=9449.962321,  \n",
    "\n",
    "B = np.arange(0, 40000, 50)\n",
    "Blen = len(B)\n",
    "M = np.arange(0, 15000, 25)\n",
    "Mlen = len(M)\n",
    "print(Blen,Mlen)\n",
    "pred=np.zeros([Blen,Mlen])\n",
    "\n",
    "\n",
    "for i in range(Blen):\n",
    "    for j in range(Mlen):\n",
    "        temp=np.array([[B[i]],[M[j]]])\n",
    "        temp=np.dot(x_b,temp)\n",
    "        temp=np.sum((temp - y)**2)\n",
    "        pred[i,j]=temp\n",
    "#         temp=(x_b.T.dot((temp - y)))\n",
    "#         pred[i,j]=LA.norm(temp)\n",
    "\n",
    "print(np.min(B))\n",
    "B, M = np.meshgrid(M, B)\n",
    "print(pred.shape, B.shape)       \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "surf = ax.plot_surface(B, M, pred, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "plt.show()\n",
    "pred_t=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: widget. Using qt instead.\n",
      "[[13142.75720298]\n",
      " [11327.08670414]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "fig, ax = plt.subplots()\n",
    "plt.contour(B, M, pred_t, 150, cmap='RdGy');\n",
    "plt.xlabel(\"Slope\", fontsize=12);\n",
    "plt.ylabel(\"Intercept\", rotation=90, fontsize=12);\n",
    "plt.plot(9449.962321, 25792.200199 , 'ro')\n",
    "\n",
    "theta_pre = np.array([[0],[0]])\n",
    "theta_new = theta_pre\n",
    "ep=1e-3\n",
    "lr =0.0001\n",
    "n_iter = 1000\n",
    "y=y.reshape((len(y), 1))\n",
    "x_b = np.c_[np.ones((len(x),1)),x]\n",
    "plt.plot(theta_pre[0], theta_pre[1], 'go')\n",
    "for it in range(n_iter):\n",
    "    #Gradient\n",
    "    pred = np.dot(x_b,theta_pre)\n",
    "    si=-lr*(x_b.T.dot((pred - y)))\n",
    "    theta_new = theta_pre + si;\n",
    "    xt=np.array([theta_pre[1],theta_new[1]])\n",
    "    yt=np.array([theta_pre[0],theta_new[0]])\n",
    "    plt.plot(theta_new[1], theta_new[0], 'go')\n",
    "    plt.plot(xt,yt,'g-')\n",
    "    theta_pre=theta_new\n",
    "#     print(theta_pre)\n",
    "    if LA.norm(si)<ep:\n",
    "        break;\n",
    "plt.show()\n",
    "print(theta_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo bidimensional del Algoritmo de gradiente descendente  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: widget. Using qt instead.\n",
      "      mpg  cylinders  displacement horsepower  weight  acceleration  \\\n",
      "0    18.0          8         307.0        130    3504          12.0   \n",
      "1    15.0          8         350.0        165    3693          11.5   \n",
      "2    18.0          8         318.0        150    3436          11.0   \n",
      "3    16.0          8         304.0        150    3433          12.0   \n",
      "4    17.0          8         302.0        140    3449          10.5   \n",
      "..    ...        ...           ...        ...     ...           ...   \n",
      "393  27.0          4         140.0         86    2790          15.6   \n",
      "394  44.0          4          97.0         52    2130          24.6   \n",
      "395  32.0          4         135.0         84    2295          11.6   \n",
      "396  28.0          4         120.0         79    2625          18.6   \n",
      "397  31.0          4         119.0         82    2720          19.4   \n",
      "\n",
      "     model year  origin                   car name  \n",
      "0            70       1  chevrolet chevelle malibu  \n",
      "1            70       1          buick skylark 320  \n",
      "2            70       1         plymouth satellite  \n",
      "3            70       1              amc rebel sst  \n",
      "4            70       1                ford torino  \n",
      "..          ...     ...                        ...  \n",
      "393          82       1            ford mustang gl  \n",
      "394          82       2                  vw pickup  \n",
      "395          82       1              dodge rampage  \n",
      "396          82       1                ford ranger  \n",
      "397          82       1                 chevy s-10  \n",
      "\n",
      "[398 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "dataset = pd.read_csv('auto-mpg.csv')\n",
    "print(dataset)\n",
    "# dataset= dataset.drop(labels=8, axis=0)\n",
    "vary=0\n",
    "var1=4\n",
    "var2=5\n",
    "\n",
    "x1 = dataset.iloc[:, var1].values #Feature matrix\n",
    "x2 = dataset.iloc[:, var2].values #Criterion Matrix \n",
    "y = dataset.iloc[:, vary].values #Criterion Matrix \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter3D(x1,x2,y)\n",
    "plt.title(\"Data  3D \")\n",
    "\n",
    "\n",
    "ax.set_xlabel(dataset.columns[var1], fontsize=12);\n",
    "ax.set_ylabel(dataset.columns[var2], rotation=90, fontsize=12);\n",
    "ax.set_zlabel(dataset.columns[vary], rotation=90, fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 3)\n",
      "(398, 1)\n",
      "[23.51457281] [-6.20451092] [0.69061318]\n"
     ]
    }
   ],
   "source": [
    "theta = np.array([[-10],[-10],[-10]])\n",
    "ep=1e-4\n",
    "lr =0.001\n",
    "n_iter = 500\n",
    "y=y.reshape((len(y), 1))\n",
    "x_b = np.c_[np.ones((len(x1),1)),x1,x2]\n",
    "#Standardization using z-score\n",
    "nf,nc=x_b.shape\n",
    "x_bs=x_b\n",
    "for it in range(1,nc):\n",
    "    m=np.mean(x_b[:,it])\n",
    "    std=np.std(x_b[:,it])\n",
    "    x_bs[:,it]=(x_b[:,it]-m)/std\n",
    "\n",
    "for it in range(n_iter):\n",
    "    #Gradient\n",
    "    pred = np.dot(x_bs,theta)\n",
    "    si=-lr*(x_bs.T.dot((pred - y)))\n",
    "    theta = theta + si\n",
    "    \n",
    "    if LA.norm(si)<ep:\n",
    "        break;\n",
    "print(theta[0],theta[1],theta[2])        \n",
    "#[23.51457281] [-6.20451092] [0.69061318]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 305)\n",
      "(209, 305)\n",
      "(209, 305)\n"
     ]
    }
   ],
   "source": [
    "x1 = np.arange(np.min(x_bs[:,1]), np.max(x_bs[:,1]), 0.02)\n",
    "x2 = np.arange(np.min(x_bs[:,2]), np.max(x_bs[:,2]), 0.02)\n",
    "plane=np.zeros([len(x1),len(x2)])\n",
    "\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        plane[i,j]=np.dot(np.c_[1,x1[i],x2[j]],theta)\n",
    "X1, X2 = np.meshgrid(x1, x2, indexing = 'ij')\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "print(plane.shape)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf = ax.plot_surface(X1,X2, plane,\n",
    "                       linewidth=0, antialiased=False,alpha=0.2)\n",
    "ax.scatter(x_bs[:,1], x_bs[:,2], y, c='r', marker='o')\n",
    "ax.set_xlabel(dataset.columns[var1], fontsize=12);\n",
    "ax.set_ylabel(dataset.columns[var2], rotation=90, fontsize=12);\n",
    "ax.set_zlabel(dataset.columns[vary], rotation=90, fontsize=12);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución cerrrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.51457286]\n",
      " [-6.20432137]\n",
      " [ 0.69080273]]\n"
     ]
    }
   ],
   "source": [
    "theta_best = np.linalg.inv(x_bs.T.dot(x_bs)).dot(x_bs.T).dot(y)\n",
    "print(theta_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
