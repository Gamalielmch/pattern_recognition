\documentclass{beamer}
\usetheme{ALUF}

\usepackage[utf8]{inputenc}
% \usepackage{palatino}
% \usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[expert]{mathdesign}
\usepackage[protrusion=true,expansion=true,tracking=true,kerning=true]{microtype}
\usepackage{xcolor}
\usepackage{tcolorbox}
\tcbuselibrary{theorems}
%% Use any fonts you like.
% \usepackage{libertine}

\title{Repaso de Álgebra lineal}
\subtitle{Reconocimiento de patrones}
\author{Gamaliel Moreno}
\date{Enero-Julio 2021}
%\institute{\url{gamalielmch@uaz.edu.mx}}

\institute{\url{gamalielmch@uaz.edu.mx}\\\url{http://pds.uaz.edu.mx/}}

\begin{document}

\begin{frame}[plain,t]
\titlepage
\end{frame}

\begin{frame}% [plain,t]
	\frametitle{Contenido}
\tableofcontents
\end{frame}

%=============================================================================================

\section{Vectores y matrices}
\subsection{Definciones}
\begin{frame}
\frametitle{Escalar}
Un escalar es un número real
\begin{equation*}
s\in \mathbb{R}
\end{equation*}
\end{frame}
%%%=============================================================================================
\begin{frame}
\frametitle{Vector}
Vector de m dimensiones $\boldsymbol{x} \in \mathbb{R}^m$ (m escalares) 
\begin{equation*}
\boldsymbol{x} = \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_m \end{bmatrix}
\end{equation*}
\end{frame}
%%%=============================================================================================
\begin{frame}
\frametitle{Vector fila}
Vector de n dimensiones $\boldsymbol{x} \in \mathbb{R}^n$ (n escalares) 
\begin{equation*}
\boldsymbol{x}^T = \begin{bmatrix} x_1 &  x_2 & \dots & x_n \end{bmatrix}
\end{equation*}
\end{frame}
%%%=============================================================================================
\begin{frame}
\frametitle{Matriz}
Matriz de $m  \times n$ $\boldsymbol{A} \in \mathbb{R}^{m\times n}$ 
\begin{equation*}
\boldsymbol{A} = \begin{bmatrix} a_{11} &  a_{12} & \dots & a_{1n}\\ a_{21} &  a_{22} & \dots & a_{2n} \\ \vdots &  \vdots & \ddots & \vdots \\ a_{m1} &  a_{m2} & \dots & a_{mn} \end{bmatrix}
\end{equation*}
\begin{itemize}
\item m: files
\item n: columnas
\item En notación $a_{ij}$ primer subíndice i es la fila y el segundo la columna
\item Todas las matrices en $\mathbb{R}^{m\times n}$ conforman un espacio lineal. Esto es $ B=\lbrace B_{i} \vert B_{i} \in \mathbb{R}^{m\times n} \rbrace$, entonces $M = \sum_{i} c_{i}B_{i}$ 

\end{itemize}
\end{frame}
%%%=============================================================================================
\begin{frame}
\frametitle{Tensor}
 Generalización de conceptos anteriores
\begin{itemize}
\item Escalar $s \in \mathbb{R}$: tensor 0
\item Vector $\boldsymbol{v} \in \mathbb{R}^n$: tensor 1
\item Matriz $\boldsymbol{M} \in \mathbb{R}^{m\times n}$: tensor 2
\item En general $\mathcal{T} \in \mathbb{R}^{n_1\times n_2 \times \cdots n_q}$ es un tensor de orden $q$
\end{itemize}
\end{frame}
%%%=============================================================================================
\begin{frame}
\frametitle{Matriz en vector}
Matriz  $\boldsymbol{A} \in \mathbb{R}^{m\times n}$ se descompone en m vectores fila
\begin{equation*}
\boldsymbol{A} = \begin{bmatrix} a_{11} &  a_{12} & \dots & a_{1n}\\ a_{21} &  a_{22} & \dots  & a_{2n} \\ \vdots &  \vdots & \ddots & \vdots \\ a_{m1} &  a_{m2} & \dots & a_{mn} \end{bmatrix} = \begin{bmatrix}	\tcboxmath[colback=blue!25!white,colframe=blue,top=0pt,left=10pt,right=10pt,bottom=0pt]{\boldsymbol{a_{1,:}}^T} \\ \tcboxmath[colback=blue!25!white,colframe=blue,top=0pt,left=10pt,right=10pt,bottom=0pt]{\boldsymbol{a_{2,:}}^T} \\ \vdots \\ \tcboxmath[colback=blue!25!white,colframe=blue,top=0pt,left=10pt,right=10pt,bottom=0pt]{\boldsymbol{a_{m,:}}^T}  \end{bmatrix}
\end{equation*}
o en vectores columna 
\begin{equation*}
\boldsymbol{A} = \begin{bmatrix} a_{11} &  a_{12} & \dots & a_{1n}\\ a_{21} &  a_{22} & \dots  & a_{2n} \\ \vdots &  \vdots & \ddots & \vdots \\ a_{m1} &  a_{m2} & \dots & a_{mn} \end{bmatrix} = \begin{bmatrix}	\tcboxmath[colback=blue!25!white,colframe=blue,top=20pt,left=0pt,right=0pt,bottom=20pt]{\boldsymbol{a_{:,1}}} & \tcboxmath[colback=blue!25!white,colframe=blue,top=20pt,left=0pt,right=0pt,bottom=20pt]{\boldsymbol{a_{:,2}}} & \vdots & \tcboxmath[colback=blue!25!white,colframe=blue,top=20pt,left=0pt,right=0pt,bottom=20pt]{\boldsymbol{a_{:,n}}}  \end{bmatrix}
\end{equation*}

\end{frame}
%%%=============================================================================================
\begin{frame}
\frametitle{Vectores como matrices}
\begin{itemize}
\item Observe que todo vector es un tipo particular de matriz 
\begin{itemize}
\item Vector fila: matriz de dimensiones $1 \times n$
\item Vector columna: matriz de dimensiones $m \times 1$
\end{itemize}
\item Propiedades de matrices aplicarán a vectores
\end{itemize}
\end{frame}
%%%=============================================================================================
\section{Operaciones matriciales}
\subsection{Definciones}
\begin{frame}
\frametitle{Matriz transpuesta 1}
Si 
\begin{equation*}
\boldsymbol{A} = \begin{bmatrix} a_{11} &  a_{12} & \dots & a_{1n}\\ a_{21} &  a_{22} & \dots & a_{2n} \\ \vdots &  \vdots & \ddots & \vdots \\ a_{m1} &  a_{m2} & \dots & a_{mn} \end{bmatrix}
\end{equation*}
entonces 
\begin{equation*}
\boldsymbol{A}^T = \begin{bmatrix} a_{11} &  a_{21} & \dots & a_{m1}\\ a_{12} &  a_{22} & \dots & a_{m2} \\ \vdots &  \vdots & \ddots & \vdots \\ a_{1n} &  a_{2n} & \dots & a_{mn} \end{bmatrix}
\end{equation*}
\begin{itemize}
\item En otras palabras, si $\boldsymbol{B}= \boldsymbol{A}^T$ entonces $b_{ij}=a_{ij}$
\item $(\boldsymbol{A}^T)^T= \boldsymbol{A}$
\item $(\boldsymbol{A}\boldsymbol{B})^T= \boldsymbol{B}^T \boldsymbol{A}^T $
\item $(\boldsymbol{A}+ \boldsymbol{B})^T= \boldsymbol{A}^T + \boldsymbol{B}^T $
\end{itemize}
\end{frame}
%%%=============================================================================================
\begin{frame}
\frametitle{Simetría y anti-simetría 1}
Matriz simétrica si $\boldsymbol{A} =\boldsymbol{A}^T$
  
\begin{equation*}
\boldsymbol{A} = \begin{bmatrix} a_{11} &  a_{21} & \dots & a_{n1}\\ a_{21} &  a_{22} & \dots & a_{n2} \\ \vdots &  \vdots & \ddots & \vdots \\ a_{n1} &  a_{n2} & \dots & a_{nn} \end{bmatrix}
\end{equation*}

es decir $a_{ij}=a_{ji}$

\begin{itemize}
\item La matriz es anti-simétrica si  $\boldsymbol{A} =-\boldsymbol{A}^T$
\item Para  cualquier matriz cuadrada $\boldsymbol{A} \in \mathbb{R}^{n\times n}$ se cumple

\begin{itemize}
\item $\boldsymbol{A}+ \boldsymbol{A}^T$ es simétrica 
\item $\boldsymbol{A}- \boldsymbol{A}^T$ es anti-simétrica
\item $\boldsymbol{A}= \boldsymbol{A}_{e}+\boldsymbol{A}_{o}= \frac{1}{2}(\boldsymbol{A}+\boldsymbol{A}^T)+\frac{1}{2}(\boldsymbol{A}-\boldsymbol{A}^T)$
\end{itemize}
\item $\mathbb{S}^{n}$ es el conjunto de todas las matrices simétricas $n\times n$
\end{itemize}
\end{frame}
%%%=============================================================================================
\begin{frame}
\frametitle{Matriz diagonal}
Una matriz es diagonal si todos los elementos son cero excepto aquellos en la diagonal 
  
\begin{equation*}
\boldsymbol{A} = \begin{bmatrix} a_{11} &   &   &  \\   &  a_{22} &   &   \\  &    & \ddots &   \\   &   &  & a_{nn} \end{bmatrix}
\end{equation*}
Se utiliza la notación $\boldsymbol{A} = diag(\underline{\boldsymbol{a}})$ y $diag(\boldsymbol{A})=\underline{\boldsymbol{a}}$ con $\underline{\boldsymbol{a}}= {[a_{11}\hspace{1em} a_{22} \hspace{1em} \cdots \hspace{1em} a_{nn} ]}^T$
\end{frame}
%%%=============================================================================================
\begin{frame}
\frametitle{Matriz identidad}
Es una matriz diagonal cuyos elementos no nulos son iguales a uno 
  
\begin{equation*}
\boldsymbol{I} = \begin{bmatrix} 1 &   &   &  \\   &  1 &   &   \\  &    & \ddots &   \\   &   &  & 1 \end{bmatrix}
\end{equation*}

\begin{itemize}
\item Se cumple $\boldsymbol{A} \boldsymbol{I} = \boldsymbol{A}  = \boldsymbol{I}\boldsymbol{A}$ ($\boldsymbol{I}$ es el elemento nuestro del producto matricial)
\item $\boldsymbol{I}= diag([1,1,\ldots, 1]^{T})$
\end{itemize}



\end{frame}

%=============================================================================================
\begin{frame}
\frametitle{Suma de matrices}
El producto $s\boldsymbol{A}$ es otra matriz con todos los componentes escalados

\begin{equation*}
s\boldsymbol{A} =s\begin{bmatrix} a_{11} &  a_{12} & \dots & a_{1n}\\ a_{21} &  a_{22} & \dots & a_{2n} \\ \vdots &  \vdots & \ddots & \vdots \\ a_{m1} &  a_{m2} & \dots & a_{mn} \end{bmatrix} = \begin{bmatrix} sa_{11} &  sa_{12} & \dots & sa_{1n}\\ sa_{21} &  sa_{22} & \dots & sa_{2n} \\ \vdots &  \vdots & \ddots & \vdots \\ sa_{m1} &  sa_{m2} & \dots & sa_{mn} \end{bmatrix} 
\end{equation*}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Producto escalar-matriz}
Suma definida para dos matrices de idéntico tamaño:
\begin{equation*}
\boldsymbol{c}=\boldsymbol{A}+\boldsymbol{B}\Leftrightarrow c_{ij}= a_{ij}+b_{ij}
\end{equation*}
\begin{equation*}
\begin{split}
 \begin{bmatrix} c_{11} &  c_{12} & \dots & c_{1n}\\ c_{21} &  c_{22} & \dots & c_{2n} \\ \vdots &  \vdots & \ddots & \vdots \\ c_{m1} &  c_{m2} & \dots & c_{mn} \end{bmatrix} = \\ \begin{bmatrix} a_{11}+b_{11} &  a_{12}+b_{12} & \dots & a_{1n}+b_{1n}\\ a_{21}+b_{21} &  a_{22}+b_{22} & \dots & a_{2n}+b_{2n} \\ \vdots &  \vdots & \ddots & \vdots \\ a_{m1}+b_{m1} &  a_{m2}+b_{m2} & \dots & a_{mn}+b_{mn} \end{bmatrix} 
 \end{split}
\end{equation*}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Combinación lineal}
Una matriz $\boldsymbol{A}$ es la combinación lineal de un conjunto de \textit{m} matrices si 

\begin{equation*}
\boldsymbol{A}= \displaystyle \sum_{i=1}^{m} s_{i}\boldsymbol{B}_{i}
\end{equation*}
donde $s_{i}$ son los coeficientes de la combinación.
\begin{itemize}
 \item El conjunto $\mathcal{B}= \lbrace \boldsymbol{B}_{i} \vert i=1 \ldots m \rbrace$ engendra un espacio lineal $\mathcal{V}$ compuesto de todas las combinaciones lineales posibles de las matrices $\mathcal{B}$
\end{itemize} 
\end{frame}

%=============================================================================================
\begin{frame}
\frametitle{Producto punto entre vectores}
\begin{itemize}
\item El producto punto está definido para dos vectores de dimensión $n$, y es un valor escalar calculado con:
\begin{equation*}
\boldsymbol{x} \cdot \boldsymbol{y} = \boldsymbol{x}^T  \boldsymbol{y}= x_{1}y_{1}+x_{2}+y_{2}+ \cdots x_{n}y_{n} = \sum_{i=1}^{n} x_{i}y_{i}
\end{equation*}
\item Interpretación relacionada con proyección entre vectores
\item El producto punto es un tipo de producto interno y por tanto se puede denotar también $\langle \boldsymbol{x}, \boldsymbol{y}\rangle$
\item Para matrices, el producto interno de Frobenius se define como:
\begin{equation*}
\langle \boldsymbol{A}, \boldsymbol{B}\rangle_{F} = \sum_{i=1}^{m}\sum_{j=1}^{n} a_{ij}b_{ij}
\end{equation*}
\end{itemize}
\end{frame}

%=============================================================================================
\begin{frame}
\frametitle{Ángulo entre dos vectores}
\begin{itemize}
\item El ángulo $\alpha$ entre dos vectores $\boldsymbol{x}$  y $\boldsymbol{y}$ está dado por 


 
\begin{equation*}
\alpha= arcos \left(  \frac{\boldsymbol{x}^T \boldsymbol{y}}{\vert \vert \boldsymbol{x} \vert \Vert \cdot \vert \vert \boldsymbol{y} \vert \vert}\right)
\end{equation*}
\item La proyección ortogonal de $\boldsymbol{y}$ sobre la dirección de $\boldsymbol{x}$ está dada por 
\begin{equation*}
y_{\boldsymbol{x}}= \frac{\boldsymbol{x}^T\boldsymbol{y}}{\vert \vert \boldsymbol{x} \vert \vert}
\end{equation*}

\item Si $\boldsymbol{x}^T\boldsymbol{y}=0$ ambos vectores son ortogonales 
\item Si $\vert \vert \boldsymbol{x} \vert \vert =1$ se dice que $\boldsymbol{x}$ está normalizado 
\item Vectores son ortonormales si son ortogonales y normalizados

\end{itemize}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Producto externo}
El producto externo está definido para dos vectores y es una matriz de dimensiones $m \times n$  con $m$ el tamaño del primer vector y $n$ el tamaño del segundo vector
\begin{equation*}
\boldsymbol{x} \boldsymbol{y}^T  =\begin{bmatrix} x_{1}y_{1} &  x_{1}y_{2} & \dots & x_{1}y_{n}\\ x_{2}y_{1} &  x_{2}y_{2} & \dots & x_{2}y_{n} \\ \vdots &  \vdots & \ddots & \vdots \\ x_{m}y_{1} &  x_{m}y_{2} & \dots & x_{m}y_{n} \end{bmatrix} 
\end{equation*}
\end{frame}

%=============================================================================================
\begin{frame}
\frametitle{Ejemplo: Uso de operaciones aritméticas 1}
Dado el vector columna $m$-dimensional $\boldsymbol{x}$ ¿con qué operaciones puede expresarse la réplica de ese vector en $n$ columnas de una matriz? ¿con qué operaciones puede expresarse la réplica de un vector fila $n$-dimensional $\boldsymbol{x}$ en $m$ filas de una matriz?
\begin{equation*}
\boldsymbol{A} = \begin{bmatrix} x_{1}  &  x_{1} & \dots & x_{1}\\ x_{2} &  x_{2} & \dots & x_{2} \\ \vdots &  \vdots & \ddots & \vdots \\ x_{m} &  x_{m} & \dots & x_{m} \end{bmatrix}
\end{equation*}
\begin{equation*}
\boldsymbol{A} = \begin{bmatrix} x_{1}  &  x_{2} & \dots & x_{n}\\ x_{1} &  x_{2} & \dots & x_{n} \\ \vdots &  \vdots & \ddots & \vdots \\ x_{1} &  x_{2} & \dots & x_{n} \end{bmatrix}
\end{equation*}

\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Ejemplo: Uso de operaciones aritméticas 1}
\begin{equation*}
\boldsymbol{A}= \left[ \boldsymbol{x} \hspace{1em} \boldsymbol{x}  \cdots \boldsymbol{x}  \right]= \boldsymbol{x} \boldsymbol{1}^T=\begin{bmatrix}  x_{1}   \\ x_{2} \\ \vdots  \\ x_{m}  \end{bmatrix}
\end{equation*}
\begin{equation*}
\boldsymbol{A} = \begin{bmatrix} x_{1}  &  x_{1} & \dots & x_{1}\\ x_{2} &  x_{2} & \dots & x_{2} \\ \vdots &  \vdots & \ddots & \vdots \\ x_{m} &  x_{m} & \dots & x_{m} \end{bmatrix}
\end{equation*}
\end{frame}

%=============================================================================================
\begin{frame}
\frametitle{Ejemplo: Uso de operaciones aritméticas 1}
\begin{equation*}
\boldsymbol{A}= \begin{bmatrix} \boldsymbol{x}^T  \\ \boldsymbol{x}^T  \\ \vdots \\ \boldsymbol{x}^T   \end{bmatrix}= \boldsymbol{1} \boldsymbol{x}^T = \begin{bmatrix} 1  \\ 1 \\ \vdots \\ 1  \end{bmatrix} [x_{1} \hspace{1em} x_{2} \cdots x_{n}]
\end{equation*}
\begin{equation*}
\boldsymbol{A} = \begin{bmatrix} x_{1}  &  x_{2} & \dots & x_{n}\\ x_{1} &  x_{2} & \dots & x_{n} \\ \vdots &  \vdots & \ddots & \vdots \\ x_{1} &  x_{2} & \dots & x_{n} \end{bmatrix}
\end{equation*}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Producto matricial}
El producto entre una matriz $\boldsymbol{A}$ de dimensiones $m \times n$ por otra matriz de $\boldsymbol{B}$ de dimensión $n\times l$ es la matriz 

 
\begin{equation*}
\boldsymbol{C}= \boldsymbol{AB}= \begin{bmatrix} \boldsymbol{a}_{1,:}^T  \\ \boldsymbol{a}_{2,:}^T  \\ \vdots \\ \boldsymbol{a}_{m,:}^T   \end{bmatrix}[\boldsymbol{b}_{:,1}^T \hspace{1em} \boldsymbol{b}_{:,2}^T \cdots \boldsymbol{b}_{:,l}^T ]
\end{equation*}
\begin{equation*}
\boldsymbol{A} = \begin{bmatrix} \boldsymbol{a}_{1,:} \cdot \boldsymbol{b}_{:,1}  & \boldsymbol{a}_{1,:} \cdot \boldsymbol{b}_{:,2}  &  \cdots & \boldsymbol{a}_{1,:} \cdot \boldsymbol{b}_{:,l} \\   \boldsymbol{a}_{2,:} \cdot \boldsymbol{b}_{:,1}  & \boldsymbol{a}_{2,:} \cdot \boldsymbol{b}_{:,2}  &  \cdots & \boldsymbol{a}_{2,:} \cdot \boldsymbol{b}_{:,l}  \\ \vdots  & \vdots   & \ddots &  \vdots  \\   \boldsymbol{a}_{m,:} \cdot \boldsymbol{b}_{:,1}  & \boldsymbol{a}_{m,:} \cdot \boldsymbol{b}_{:,2}  &  \cdots & \boldsymbol{a}_{m,:} \cdot \boldsymbol{b}_{:,l} \end{bmatrix}
\end{equation*}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Propiedades el producto matricial}
\begin{itemize}
\item El producto matricial NO es conmutativo 
\begin{equation*}
\boldsymbol{AB} \neq \boldsymbol{BA}
\end{equation*}
\item Si las dimensiones permiten, el producto matricial SÍ es asociativo 
\begin{equation*}
(\boldsymbol{AB})\boldsymbol{C} = \boldsymbol{A}(\boldsymbol{BC})
\end{equation*}
\item Si las dimensiones permiten, el producto matricial SÍ es distributivo
\begin{equation*}
(\boldsymbol{A}+\boldsymbol{B})\boldsymbol{C} = \boldsymbol{A}\boldsymbol{C}+ \boldsymbol{B}\boldsymbol{C}
\end{equation*}
\end{itemize}
\end{frame}
%=============================================================================================
\subsection{Interpretaciones}
\begin{frame}
\frametitle{Interpretaciones del producto matricial 1}
\begin{itemize}
\item Observe primero el producto matriz vector 
\begin{equation*}
\boldsymbol{c} =\boldsymbol{Ab}=\begin{bmatrix} \boldsymbol{a}_{1,:}^T  \\ \boldsymbol{a}_{2,:}^T  \\ \vdots \\ \boldsymbol{a}_{m,:}^T   \end{bmatrix} \boldsymbol{b} = \begin{bmatrix} \boldsymbol{a}_{1,:}^T \boldsymbol{b}  \\ \boldsymbol{a}_{2,:}^T \boldsymbol{b} \\ \vdots \\ \boldsymbol{a}_{m,:}^T \boldsymbol{b}  \end{bmatrix}= \begin{bmatrix} \boldsymbol{a}_{1,:} \cdot \boldsymbol{b}  \\ \boldsymbol{a}_{2,:} \cdot \boldsymbol{b} \\ \vdots \\ \boldsymbol{a}_{m,:} \cdot \boldsymbol{b}  \end{bmatrix} = \begin{bmatrix} c_{1}  \\ c_{2}  \\ \vdots \\ c_{m}   \end{bmatrix}
\end{equation*}
\item el producto matriz-vector mapea un vector en otro

\item En el producto matriz-matriz $\boldsymbol{C}=\boldsymbol{A}\boldsymbol{B}$, si $\boldsymbol{b}_{:,j}$ es la j-ésima columna de $\boldsymbol{B}$ entonces el patrón anterior se cumple para la j-ésima columna $\boldsymbol{c}_{:,j}$ del resultado.
\end{itemize}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Producto como combinación lineal de columnas 1}
\begin{itemize}
\item Otra forma de ver el producto matriz-vector es como combinación lineal de las columnas de la matriz:
 
\begin{equation*}
\boldsymbol{c} =\boldsymbol{Ab}=\begin{bmatrix} \boldsymbol{a}_{:,1}  & \boldsymbol{a}_{:,2} & \cdots & \boldsymbol{a}_{:,n}   \end{bmatrix} \begin{bmatrix} b_{1}  \\ b_{2}  \\ \vdots \\ b_{n}  \end{bmatrix} 
\end{equation*}

\begin{equation*}
=b_{1}\boldsymbol{a}_{:,1}  + b_{2}\boldsymbol{a}_{:,2} + \cdots + b_{n}\boldsymbol{a}_{:,n} 
\end{equation*}

\item Observe la similitud con el producto punto
\item El espacio engendrado por las columnas de $\boldsymbol{A}$ se denomina espacio columna de  $\boldsymbol{A}$
\item El espacio columna se conoce también como el alcance columna de $\boldsymbol{A}$ (range)
\item La dimensión del alcance es el rango (rank)
\end{itemize}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Producto vector matriz}
\begin{itemize}
\item Observe ahora el producto vector-matriz:
 
\begin{equation*}
\boldsymbol{c}^T =\boldsymbol{b}^T\boldsymbol{A}= \boldsymbol{b}^T \begin{bmatrix} \boldsymbol{a}_{:,1}  & \boldsymbol{a}_{:,2} & \cdots & \boldsymbol{a}_{:,n}   \end{bmatrix}
\end{equation*}
\begin{equation*}
=\begin{bmatrix} \boldsymbol{b} \cdot \boldsymbol{a}_{:,1}  & \boldsymbol{b} \cdot \boldsymbol{a}_{:,2} & \cdots & \boldsymbol{b} \cdot \boldsymbol{a}_{:,n}   \end{bmatrix} 
\end{equation*}

\item En el producto matriz-matriz $\boldsymbol{AB}$, si $\boldsymbol{a}_{j,:}$ es la j-ésima fila de $\boldsymbol{A}$ entonces el patrón anterior se cumple para la j-ésima fila del resultado
\end{itemize}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Producto como combinación lineal de filas 1}
\begin{itemize}
\item Otra forma de ver el producto vector-matriz es como combinación lineal de los vectores fila 
 
\begin{equation*}
\boldsymbol{c}^T =\boldsymbol{b}^T\boldsymbol{A}= \begin{bmatrix} b_1  & b_2 & \cdots & b_n   \end{bmatrix} \begin{bmatrix} \boldsymbol{a}_{1,:}^T  \\ \boldsymbol{a}_{2,:}^T \\ \cdots \\ \boldsymbol{a}_{n,:}^T   \end{bmatrix}= 
\end{equation*}
\begin{equation*}
=b_1\boldsymbol{a}_{1,:}^T +b_2\boldsymbol{a}_{2,:}^T+\cdots+b_n\boldsymbol{a}_{n,:}^T
\end{equation*}

\item Observe la similitud con el producto punto.
\end{itemize}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Producto como combinación lineal de filas 2}
\begin{theorem}{Dos posibles interpretaciones}
Lo anterior implica que el producto de dos matrices puede interpretarse como combinaciones lineales de las columnas de la primera matriz o de las filas de la segunda matriz
\end{theorem}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Producto de Hadamard}
\begin{itemize}
\item Producto de Hadamard, de Schur, o elemento por elemento
\item Denotado por $\boldsymbol{A} \odot \boldsymbol{B}$ 
\item aplica para dos matrices del mismo tamaño
\begin{equation*}
\boldsymbol{A} \odot \boldsymbol{B} = \begin{bmatrix} a_{11} &  a_{12} & \dots & a_{1n}\\ a_{21} &  a_{22} & \dots & a_{2n} \\ \vdots &  \vdots & \ddots & \vdots \\ a_{m1} &  a_{m2} & \dots & a_{mn} \end{bmatrix} \odot \begin{bmatrix} b_{11} &  b_{12} & \dots & b_{1n}\\ b_{21} &  b_{22} & \dots & b_{2n} \\ \vdots &  \vdots & \ddots & \vdots \\ b_{m1} &  b_{m2} & \dots & b_{mn} \end{bmatrix}
\end{equation*}

\begin{equation*}
=\begin{bmatrix} a_{11}b_{11} &  a_{12}b_{12} & \dots & a_{1n} b_{1n}\\ a_{21}b_{21} &  a_{22}b_{22} & \dots & a_{2n}b_{2n} \\ \vdots &  \vdots & \ddots & \vdots \\ a_{m1}b_{m1} &  a_{m2}b_{m2}  & \dots & a_{mn}b_{mn} \end{bmatrix} 
\end{equation*}
\end{itemize}
\end{frame}
%=============================================================================================
\section{Gradientes Matriciales}
\subsection{Gradiente y traza}
\begin{frame}
\frametitle{Derivadas con matrices y la traza}
\begin{itemize}
\item Sea $\boldsymbol{A}$ una matriz de tamano $m\times n$ y $f:\mathbb{R}^{m\times n} \rightarrow \mathbb{R}$ una función que mapea matrices como $\boldsymbol{A}$ avalores reales 

\item El gradiente de la función escalar $f$ es la matriz
 
\begin{equation*}
\nabla_{\boldsymbol{A}}f(\boldsymbol{A})= \begin{bmatrix} \frac{\partial f}{\partial a_{11}} & \frac{\partial f}{\partial a_{12}} & \dots & \frac{\partial f}{\partial a_{1n}} \\ \vdots &  \vdots & \ddots & \vdots \\ \frac{\partial f}{\partial a_{m1}} &  \frac{\partial f}{\partial a_{m2}} & \dots & \frac{\partial f}{\partial a_{mn}} \end{bmatrix}  \boldsymbol{A} =  \begin{bmatrix} a_{11} &  a_{12} & \dots & a_{1n} \\ \vdots &  \vdots & \ddots & \vdots \\ a_{m1} &  a_{m2} & \dots & a_{mn} \end{bmatrix}
\end{equation*}

\item La traza de la matriz cuadrada $\boldsymbol{A}$ de tamaño $n\times n$ es 

\begin{equation*}
tr \boldsymbol{A}= \sum_{i=1}^{n}a_{ii}
\end{equation*}
\item Un escalar s (matriz $1\times 1$) tiene $tr s =s$
\end{itemize}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Propiedades de la traza}

\begin{itemize}
\item $tr (\boldsymbol{A}+\boldsymbol{B})= tr \boldsymbol{A}+tr\boldsymbol{B}$  
\item $tr (c\boldsymbol{A})= c tr \boldsymbol{A}$
\item $tr \boldsymbol{A}= tr \boldsymbol{A}^T$
\item Si $\boldsymbol{AB}$ es cuadrada entonces $tr \boldsymbol{AB} = \boldsymbol{BA}$ 
\begin{equation*}
tr \boldsymbol{AB}= \sum_{i=1}^{n}\sum_{j=1}^{m} a_{ij}b_{ij}= \sum_{j=1}^{m}\sum_{i=1}^{n} b_{ij}a_{ij} = tr \boldsymbol{BA}
\end{equation*}

\item Corolario
\begin{itemize}
\item $tr \boldsymbol{ABC}=tr \boldsymbol{CAB}= tr \boldsymbol{BCA}$
\item $tr \boldsymbol{ABCD}=tr \boldsymbol{DABC}=tr \boldsymbol{CDAB}=tr \boldsymbol{BCDA}$
\end{itemize}
\end{itemize}
\end{frame}
%=============================================================================================
\begin{frame}
\frametitle{Combinando traza con derivadas}

\begin{enumerate}


\item $ \nabla_{\boldsymbol{A}}tr\boldsymbol{AB}=\boldsymbol{B}^T $
\item $ \nabla_{\boldsymbol{A}^T}f(\boldsymbol{A})= (\nabla_{\boldsymbol{A}}f(\boldsymbol{A}))^T $
\item $\nabla_{\boldsymbol{A}} tr \boldsymbol{ABA}^T\boldsymbol{C}= \boldsymbol{CAB}+ \boldsymbol{C}^T \boldsymbol{AB}^T$
\item $\nabla_{\boldsymbol{A}} \vert \boldsymbol{A}\vert=\vert \boldsymbol{A}\vert(\boldsymbol{A}^{-1})^T$ 

\vspace{2em}
Combinando 2 y 3 


\end{enumerate}
\begin{itemize}
\item $ \nabla_{\boldsymbol{A}^T}tr \boldsymbol{ABA}^T \boldsymbol{C}= \boldsymbol{B}^T\boldsymbol{A}^T\boldsymbol{C}^T+\boldsymbol{B}\boldsymbol{A}^T\boldsymbol{C}$
\end{itemize}


\end{frame}
%=============================================================================================
\subsection{Derivación de ecuaciones normales}
\begin{frame}
\frametitle{Ecuaciones normales en regresión lineal}
\begin{itemize}
\item Caso particular de regresión lineal se resuelve con ecuaciones normales 
\item Usaremos lo anterior para derivación directa
\end{itemize}
\end{frame}

%=============================================================================================
\begin{frame}
\frametitle{Replanteando mínimos cuadrados }
\begin{itemize}
\item Buscamos $\boldsymbol{\theta}$ que minimiza $J(\boldsymbol{\theta})$
\item Reescribiendo $J(\boldsymbol{\theta})$ en forma matricial 
\end{itemize}
Sea $\boldsymbol{X}$ la matriz de diseño de tamaño $m\times n+1$
 \begin{equation*}
 \boldsymbol{X}= \begin{bmatrix} x^{(1)T} \\ x^{(2)T }\\ \vdots \\ x^{(m)T}   \end{bmatrix} 
 \end{equation*}
sea $\boldsymbol{y}$ el vector de valores objetivo:
 \begin{equation*}
 \boldsymbol{y}= \begin{bmatrix} y^{(1)} & y^{(2)} & \cdots & y^{(m)}   \end{bmatrix} 
 \end{equation*}
\end{frame}
%=============================================================================================

\begin{frame}
\frametitle{Replanteando mínimos cuadrados }
Puesto que 

\begin{equation*}
\boldsymbol{X\theta}-\boldsymbol{y}=  \begin{bmatrix} x^{(1)T}\boldsymbol{\theta} \\ x^{(2)T }\boldsymbol{\theta}\\ \vdots \\ x^{(m)T}\boldsymbol{\theta}   \end{bmatrix} - \begin{bmatrix} y^{(1)} \\ y^{(2)} \\ \cdots \\ y^{(m)}   \end{bmatrix}=  \begin{bmatrix} x^{(1)T}\boldsymbol{\theta}- y^{(1)}\\ x^{(2)T }\boldsymbol{\theta}-  y^{(2)}\\ \vdots \\ x^{(m)T}\boldsymbol{\theta}- y^{(m)}   \end{bmatrix}
\end{equation*}
Entonces usando $\boldsymbol{v}^T \boldsymbol{v}= \vert\vert \boldsymbol{v} \vert\vert ^{2}= \sum_{i}v_i^2 $

\begin{equation*}
J(\boldsymbol{\theta})= \frac{1}{2} \sum_{i=1}^{m}{(x^{(i)T}\boldsymbol{\theta} - y^{(i)})^2} =\frac{1}{2}\vert\vert \boldsymbol{X\theta}- \boldsymbol{y}\vert\vert^{2}
\end{equation*} 
\begin{equation*}
=\frac{1}{2} (\boldsymbol{X\theta}- \boldsymbol{y})^{T} (\boldsymbol{X\theta}- \boldsymbol{y})
\end{equation*}
 $\frac{1}{2} (\boldsymbol{X\theta}- \boldsymbol{y})^{T} (\boldsymbol{X\theta}- \boldsymbol{y})$ esto es un escalar por lo tanto $\frac{1}{2} (\boldsymbol{X\theta}- \boldsymbol{y})^{T} (\boldsymbol{X\theta}- \boldsymbol{y})= \frac{1}{2} tr (\boldsymbol{X\theta}- \boldsymbol{y})^{T} (\boldsymbol{X\theta}- \boldsymbol{y})$
\end{frame}
%=============================================================================================

\begin{frame}
\frametitle{Replanteando mínimos cuadrados}
\begin{itemize}
\item El mínimo se encuentra buscando $\nabla_{\boldsymbol{\theta}}J(\boldsymbol{\theta})=0$
\begin{equation*}
\nabla_{\boldsymbol{\theta}}J(\boldsymbol{\theta})=\nabla_{\boldsymbol{\theta}} \frac{1}{2} (\boldsymbol{X\theta}- \boldsymbol{y})^{T} (\boldsymbol{X\theta}- \boldsymbol{y})\doteq 0
\end{equation*}
\begin{equation*}
=\frac{1}{2}\nabla_{\boldsymbol{\theta}}(\boldsymbol{\theta}^T \boldsymbol{X}^T\boldsymbol{X} \boldsymbol{\theta}-\boldsymbol{\theta}^T \boldsymbol{X}^T \boldsymbol{y}-  \boldsymbol{y}^T \boldsymbol{X} \boldsymbol{\theta} +  \boldsymbol{y}\boldsymbol{y}^T)
\end{equation*}

y puesto que el término entre paréntesis es un escalar real
\begin{equation*}
=\frac{1}{2}\nabla_{\boldsymbol{\theta}} tr(\boldsymbol{\theta}^T \boldsymbol{X}^T\boldsymbol{X} \boldsymbol{\theta}-\boldsymbol{\theta}^T \boldsymbol{X}^T \boldsymbol{y}-  \boldsymbol{y}^T \boldsymbol{X} \boldsymbol{\theta} +  \boldsymbol{y}\boldsymbol{y}^T)
\end{equation*}
\begin{equation*}
=\frac{1}{2}\nabla_{\boldsymbol{\theta}}(tr\boldsymbol{\theta}^T \boldsymbol{X}^T\boldsymbol{X} \boldsymbol{\theta}- 2tr \boldsymbol{y}^T \boldsymbol{X} \boldsymbol{\theta})
\end{equation*}
\end{itemize}
\end{frame}
%=============================================================================================

\begin{frame}
\frametitle{Replanteando mínimos cuadrados}
usando $ \nabla_{\boldsymbol{A}^T}tr \boldsymbol{ABA}^T \boldsymbol{C}= \boldsymbol{B}^T\boldsymbol{A}^T\boldsymbol{C}^T+\boldsymbol{B}\boldsymbol{A}^T\boldsymbol{C}$ con $\boldsymbol{A}= \boldsymbol{\theta}^T$, $\boldsymbol{B}=\boldsymbol{X}^t\boldsymbol{X}$ y $\boldsymbol{C}=I$
\begin{equation*}
\begin{split}
\nabla_{\boldsymbol{\theta}}J(\boldsymbol{\theta})& = \frac{1}{2}\nabla_{\boldsymbol{\theta}}(tr\boldsymbol{\theta}^T \boldsymbol{X}^T\boldsymbol{X} \boldsymbol{\theta}- 2tr \boldsymbol{y}^T \boldsymbol{X} \boldsymbol{\theta}) \\
& = \frac{1}{2} (\boldsymbol{X}^T\boldsymbol{X} \boldsymbol{\theta} + \boldsymbol{X}^T\boldsymbol{X} \boldsymbol{\theta} - 2 \boldsymbol{X}^T\boldsymbol{y})\\
& = \boldsymbol{X}^T\boldsymbol{X} \boldsymbol{\theta} - \boldsymbol{X}^T\boldsymbol{y}\\
&= 0
\end{split}
\end{equation*}
Con lo que se obtienen las ecuaciones normales 
\begin{equation*}
\begin{split}
\boldsymbol{X}^T\boldsymbol{X} \boldsymbol{\theta} & = \boldsymbol{X}^T\boldsymbol{y}\\
\boldsymbol{\theta}& = (\boldsymbol{X}^T\boldsymbol{X})^{-1} \boldsymbol{X}^T \boldsymbol{y}
\end{split}
\end{equation*}
\begin{itemize}
\item $\boldsymbol{\theta} = (\boldsymbol{X}^T\boldsymbol{X})^{-1} \boldsymbol{X}^T \boldsymbol{y}$ es la solución cerrada
\end{itemize}
\end{frame}
%=============================================================================================

\begin{frame}
\frametitle{Replanteando mínimos cuadrados}
\begin{itemize}
\item $(\boldsymbol{X}^T\boldsymbol{X})^{-1} \boldsymbol{X}^T$ se conoce como la matriz seudoinversa de $\boldsymbol{X}$o seudoinversa de Moore-Penrose denotada con $\boldsymbol{X}^{\dagger}$:
\begin{equation*}
\boldsymbol{\theta}=\boldsymbol{X}^{\dagger}\boldsymbol{y}
\end{equation*}
\end{itemize}
\end{frame}
%=============================================================================================
%=============================================================================================
\end{document}
